If choose \texttt{Holiday} as the splitting attribute:
\begin{equation*}
	Gain(H) = Entropy(S) - \sum \frac{|S_v|}{|S|}Entropy(S_v)=
\end{equation*}
\begin{equation*}
	Entropy(S) - \{\frac{21}{50}[-\frac{20}{21}\log_{10}(\frac{20}{21})-\frac{1}{21}\log_{10}(\frac{1}{21})] + \frac{29}{50}[-\frac{15}{29}\log_{10}(\frac{15}{29})-\frac{14}{29}\log_{10}(\frac{14}{29})]\}
\end{equation*}
\begin{equation*}
	 = Entropy(S)-0.209
\end{equation*}
If choose \texttt{Exam Tomorrow} as the splitting attribute:
\begin{equation*}
	Gain(H) = Entropy(S) - \sum \frac{|S_v|}{|S|}Entropy(S_v)=
\end{equation*}
\begin{equation*}
	Entropy(S) - \{\frac{15}{50}[-\frac{10}{15}\log_{10}(\frac{10}{15})-\frac{5}{15}\log_{10}(\frac{5}{15})] + \frac{35}{50}[-\frac{25}{35}\log_{10}(\frac{25}{35})-\frac{10}{35}\log_{10}(\frac{10}{35})]\}
\end{equation*}
\begin{equation*}
	 = Entropy(S)-0.265
\end{equation*}
Thus, I will choose \texttt{Holiday} to get the highest information gain.

